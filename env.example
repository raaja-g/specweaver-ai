# SpecWeaver Environment Configuration
# Copy this file to .env and fill in your actual API keys

# LLM Provider API Keys (in fallback order: Groq -> Gemini -> OpenAI)
GROQ_API_KEY=your_groq_api_key_here
GOOGLE_API_KEY=your_google_gemini_api_key_here  
OPENAI_API_KEY=your_openai_api_key_here

# Redis Configuration (for async workers)
REDIS_URL=redis://redis:6379/0

# Target Application URLs
TARGET_API_URL=https://luma.enablementadobe.com
TARGET_UI_URL=https://luma.enablementadobe.com/content/luma/us/en.html

# Optional: Cursor CLI path (if using Cursor CLI as LLM provider)
CURSOR_CLI_PATH=/usr/local/bin/cursor

# Optional: Database URL (if using persistent metrics storage)
DATABASE_URL=sqlite:///artifacts/specweaver.db

# Optional: GitHub integration for auto-PR
GITHUB_TOKEN=your_github_token_here
GITHUB_REPO=your-username/your-repo

# Optional: Slack integration for notifications  
SLACK_WEBHOOK_URL=your_slack_webhook_url_here

# Security: Secret key for session management
SECRET_KEY=your-secret-key-here-change-this-in-production

# Development vs Production mode
ENVIRONMENT=development
DEBUG=true

# Optional: Vector DB configuration (if implementing)
# PINECONE_API_KEY=your_pinecone_api_key_here
# PINECONE_ENVIRONMENT=us-west1-gcp

# Browser Configuration for UI Tests
BROWSER=chromium
HEADLESS=false
BROWSER_TIMEOUT=30000
VIEWPORT_WIDTH=1280
VIEWPORT_HEIGHT=720

# Test Execution Configuration
API_MODE=mock
UI_MODE=real
PARALLEL_WORKERS=2
